{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6969416,"sourceType":"datasetVersion","datasetId":4004281}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:24:27.810731Z","iopub.execute_input":"2025-08-25T05:24:27.811038Z","iopub.status.idle":"2025-08-25T05:24:27.829472Z","shell.execute_reply.started":"2025-08-25T05:24:27.811017Z","shell.execute_reply":"2025-08-25T05:24:27.828425Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/movielens-1m/movies.csv\n/kaggle/input/movielens-1m/ratings.csv\n/kaggle/input/movielens-1m/users.csv\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"#Import Libraries (Updated)\nimport pandas as pd\nimport numpy as np\nimport re\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom surprise import SVD, Dataset, Reader\nfrom surprise.model_selection import cross_validate\nfrom surprise import accuracy\nfrom surprise.model_selection import train_test_split as surprise_train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\n%matplotlib inline\n\n# Set visualization style\nplt.style.use('seaborn')\nsns.set_palette('pastel')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:24:27.831005Z","iopub.execute_input":"2025-08-25T05:24:27.831473Z","iopub.status.idle":"2025-08-25T05:24:27.841612Z","shell.execute_reply.started":"2025-08-25T05:24:27.831451Z","shell.execute_reply":"2025-08-25T05:24:27.840772Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/4144729910.py:19: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n  plt.style.use('seaborn')\n","output_type":"stream"}],"execution_count":96},{"cell_type":"markdown","source":"# Load data and Explore Data","metadata":{}},{"cell_type":"code","source":"#Load Data \nmovies = pd.read_csv(\"/kaggle/input/movielens-1m/movies.csv\", sep=\",\", engine=\"python\", encoding=\"latin-1\",header=0,\n                     names=[\"movieId\", \"title\", \"genres\"])\nratings = pd.read_csv(\"/kaggle/input/movielens-1m/ratings.csv\", sep=\",\", engine=\"python\", encoding=\"latin-1\",header=0,\n                      names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\nusers = pd.read_csv(\"/kaggle/input/movielens-1m/users.csv\", sep=\",\", engine=\"python\", encoding=\"latin-1\",header=0,\n                    names=[\"userId\", \"gender\", \"age\", \"occupation\", \"zip\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Movies Dataset Shape:\", movies.shape)\nprint(\"Ratings Dataset Shape:\", ratings.shape)\nprint(\"Users Dataset Shape:\", users.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"movies.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ratings.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"users.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"movies = movies[movies['title'] != \"title\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)', expand=False)\nmovies['year'] = pd.to_numeric(movies['year'], errors='coerce')\n\nprint(movies[['title', 'year']].head(10))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = ratings.merge(movies, on=\"movieId\", how=\"left\")\n\ndf = df.merge(users, on=\"userId\", how=\"left\")\n\n\ndf.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def clean_title(title):\n    if isinstance(title, str):\n        return re.sub(\"[^a-zA-Z0-9 ]\", \"\", title)   # remove special chars\n    else:\n        return \"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"movies = movies.dropna(subset=[\"title\"])\n\nmovies_clean = movies.copy()\nmovies_clean[\"title\"] = movies_clean[\"title\"].apply(clean_title)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmovies_clean[\"genres\"] = movies_clean[\"genres\"].fillna(\"\").astype(str)\n\nmovies_clean[\"genres\"] = movies_clean[\"genres\"].str.split(\"|\")\n\nmovies_clean = movies_clean[movies_clean[\"genres\"].apply(lambda x: \"(no genres listed)\" not in x)]\n\nmovies_clean[\"genres_text\"] = movies_clean[\"genres\"].apply(lambda x: \" \".join(x))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ratings_clean = ratings.drop(\"timestamp\", axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"âœ… Clean Movies Dataset: {movies_clean.shape[0]} movies\")\nprint(f\"âœ… Clean Ratings Dataset: {ratings_clean.shape[0]} ratings\")\nprint(f\"âœ… Unique Users: {ratings_clean['userId'].nunique()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isnull().sum())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = df.select_dtypes(include=np.number).columns.tolist()\ncat_cols = df.select_dtypes(include=['object']).columns.tolist()\n\nfor col in num_cols:\n    mean_val = df[col].median()\n    df[col].fillna(mean_val, inplace=True)\n\nfor col in cat_cols:\n    mode_val = df[col].mode()[0]\n    df[col].fillna(mode_val, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in df.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Final Validation\nif df is not None:\n    print(\"\\nðŸ” Final Data Overview:\")\n    print(f\"Total records: {len(df)}\")\n    print(f\"Columns ({len(df.columns)}): {list(df.columns)}\")\n    print(\"\\nðŸ“Š Sample Data:\")\n    display(df.head(3))\n    \n    print(\"\\nðŸ§® Basic Stats:\")\n    print(df[['rating', 'age', 'year']].describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA (Exploratory Data Analysis) and Visualization","metadata":{}},{"cell_type":"code","source":"#Basic Data Overview\nprint(\"ðŸ“Š Data Overview:\")\nprint(\"1. Users Data:\")\nprint(users.info())\nprint(\"\\n2. Movies Data:\")\nprint(movies.info())\nprint(\"\\n3. Ratings Data:\")\nprint(ratings.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Ratings Distribution Analysis\nplt.figure(figsize=(10, 6))\nsns.countplot(x='rating', data=ratings)\nplt.title('Distribution of Movie Ratings', fontsize=14)\nplt.xlabel('Rating Score (1-5)')\nplt.ylabel('Count')\nplt.show()\n\n# Calculate statistics\nprint(\"\\nðŸ“ˆ Ratings Statistics:\")\nprint(ratings['rating'].describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #User Demographics Analysis\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Gender Distribution\nsns.countplot(x='gender', data=users, ax=ax1)\nax1.set_title('Gender Distribution')\n\n# Age Distribution\nsns.histplot(x='age', data=users, bins=20, ax=ax2)\nax2.set_title('age Distribution')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Movie Genres Analysis\n# Count individual genres\ngenre_counts = movies['genres'].str.split('|').explode().value_counts()\n\nplt.figure(figsize=(12, 8))\ngenre_counts.plot(kind='barh')\nplt.title('Most Common Movie Genres', fontsize=14)\nplt.xlabel('Number of Movies')\nplt.ylabel('Genre')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Word Cloud for Movie Titles\n# Combine all titles into one text\nall_titles = ' '.join(movies['title'].values)\n\n# Generate word cloud\nwordcloud = WordCloud(width=800, height=400, \n                     background_color='white').generate(all_titles)\n\nplt.figure(figsize=(12, 6))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Most Frequent Words in Movie Titles', fontsize=14)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# User Engagement Analysis\nuser_activity = ratings['userId'].value_counts()\n\nplt.figure(figsize=(12, 6))\nsns.histplot(user_activity, bins=50)\nplt.title('Distribution of Ratings per User')\nplt.xlabel('Number of Ratings Given')\nplt.ylabel('Number of Users')\nplt.show()\n\nprint(\"\\nTop 5 Most Active Users:\")\nprint(user_activity.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Movie Popularity Analysis\nmovie_popularity = ratings['movieId'].value_counts()\n\nplt.figure(figsize=(12, 6))\nsns.histplot(movie_popularity, bins=50)\nplt.title('Distribution of Ratings per Movie')\nplt.xlabel('Number of Ratings Received')\nplt.ylabel('Number of Movies')\nplt.show()\n\nprint(\"\\nTop 5 Most Rated Movies:\")\ntop_movies = movie_popularity.head().index.tolist()\nprint(movies[movies['movieId'].isin(top_movies)]['title'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Building User-Based Collaborative Filtering","metadata":{}},{"cell_type":"code","source":"# Make sure the rating is numbers.\nratings['rating'] = pd.to_numeric(ratings['rating'], errors='coerce')\n\n# User-Item Matrix\nuser_item_matrix = ratings.pivot_table(\n    index='userId', \n    columns='movieId', \n    values='rating'\n)\n\nprint(\"User-Item Matrix built successfully!\")\nprint(\"Shape:\", user_item_matrix.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_ratings(user_item_matrix):\n    \"\"\"\n    Normalizing user ratings by removing the average rating of each user \n    improves the accuracy of the similarity calculation between users.\n    \"\"\"\n    user_means = user_item_matrix.mean(axis=1)\n    normalized_matrix = user_item_matrix.sub(user_means, axis=0)\n    return normalized_matrix.fillna(0)\n\n#  Applay Normalization on the matrix \nuser_item_normalized = normalize_ratings(user_item_matrix)\nuser_item_filled = user_item_normalized.fillna(0)\n\nprint(\"Data normalized successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fill NaN with 0 for similarity calc\nuser_item_filled = user_item_matrix.fillna(0)\n\n# Compute user-user similarity\nuser_similarity = cosine_similarity(user_item_filled)\nuser_similarity_df = pd.DataFrame(user_similarity, \n                                  index=user_item_matrix.index, \n                                  columns=user_item_matrix.index)\n\n\nprint(\"User Similarity Matrix ready!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute item-item similarity\nitem_similarity = cosine_similarity(user_item_filled.T)\nitem_similarity_df = pd.DataFrame(item_similarity, \n                                  index=user_item_matrix.columns, \n                                  columns=user_item_matrix.columns)\n\nprint(\"Item Similarity Matrix ready!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def handle_new_user(user_id, user_item_matrix, movies, top_n=5):\n    \"\"\"\n    Dealing with new users by recommending \n    the most popular or highest-rated movies.\n    \"\"\"\n    if user_id not in user_item_matrix.index:\n        print(f\"User {user_id} is new. Returning popular movies.\")\n        \n        #Finding the highest-rated movies\n        movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n        movie_stats = movie_stats[movie_stats['count'] > 10]  # Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 10 ØªÙ‚ÙŠÙŠÙ…Ø§Øª\n        \n        # Ranking movies based on average rating and number of ratings.\n        movie_stats['score'] = movie_stats['mean'] * np.log1p(movie_stats['count'])\n        top_movies = movie_stats.sort_values('score', ascending=False).head(top_n)\n        \n        return movies[movies['movieId'].isin(top_movies.index)]['title'].tolist()\n    return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def recommend_movies_user(user_id, user_item_matrix, user_similarity_df, movies, top_n=5):\n    \"\"\"\n user_id: The user ID for recommendations\n user_item_matrix: User Ã— Movie matrix\n user_similarity_df: User similarity matrix\n movies: Movies table\n (movieId â†’ title)top_n: Number of recommendations\n    \"\"\"\n    \n    #Checking the new user\n    popular_movies = handle_new_user(user_id, user_item_matrix, movies, top_n)\n    if popular_movies is not None:\n        return popular_movies\n    \n    #Ratings of this user\n    user_ratings = user_item_matrix.loc[user_id]\n    \n    #Users similar to this user\n    similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:11]  # top 10 neighbors\n    \n    # Weighted ratings prediction\n    weighted_scores = pd.Series(dtype=float)\n    for neighbor_id, sim_score in similar_users.items():\n        neighbor_ratings = user_item_matrix.loc[neighbor_id]\n        \n        # Weigh the rating of the neighbor by similarity.\n        weighted_scores = weighted_scores.add(neighbor_ratings * sim_score, fill_value=0)\n    \n    # Normalize by sum of similarities\n    sim_sums = similar_users.sum()\n    predicted_ratings = weighted_scores / sim_sums\n    \n    #Remove movies already watched by user\n    already_seen = user_ratings[user_ratings.notna()].index\n    predicted_ratings = predicted_ratings.drop(already_seen, errors='ignore')\n    \n    #Get top recommendations\n    top_movies = predicted_ratings.sort_values(ascending=False).head(top_n)\n    \n    return movies.set_index(\"movieId\").loc[top_movies.index][\"title\"].tolist()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def improved_item_based_recommendations(movie_input, movies, item_similarity_df, top_n=5, min_similarity=0.2):\n    \"\"\"\n    Enhanced item-based recommendation system with better handling\n    \"\"\"\n    try:\n        # Handle both movie ID and movie title inputs\n        if isinstance(movie_input, str):\n            # Search for movie by title\n            movie_match = movies[movies['title'].str.contains(movie_input, case=False, na=False)]\n            if len(movie_match) == 0:\n                print(f\"Movie '{movie_input}' not found. Returning popular movies instead.\")\n                return get_popular_movies(movies, top_n)\n            movie_id = movie_match.iloc[0]['movieId']\n        else:\n            # Use movie ID directly\n            movie_id = movie_input\n        \n        # Check if movie exists in similarity matrix\n        if movie_id not in item_similarity_df.columns:\n            print(f\"Movie ID {movie_id} not in similarity matrix. Returning popular movies.\")\n            return get_popular_movies(movies, top_n)\n        \n        # Get similarity scores with minimum threshold\n        sim_scores = item_similarity_df[movie_id]\n        sim_scores = sim_scores[sim_scores >= min_similarity]\n        \n        # Remove the movie itself and sort results\n        sim_scores = sim_scores.drop(movie_id, errors='ignore').sort_values(ascending=False)\n        \n        if len(sim_scores) == 0:\n            # Fallback to popular movies if no similar movies found\n            print(\"No similar movies found. Returning popular movies.\")\n            return get_popular_movies(movies, top_n)\n        \n        # Get top recommendations\n        top_movies = sim_scores.head(top_n).index\n        return movies[movies['movieId'].isin(top_movies)][['movieId', 'title', 'genres']]\n        \n    except Exception as e:\n        print(f\"Error in recommendation: {e}\")\n        return get_popular_movies(movies, top_n)\n\ndef get_popular_movies(movies, top_n=5):\n    \"\"\"\n    Get popular movies as fallback recommendation\n    \"\"\"\n    # Calculate movie popularity based on rating count and average\n    movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n    movie_stats = movie_stats[movie_stats['count'] > 10]  # Minimum 10 ratings\n    movie_stats['score'] = movie_stats['mean'] * np.log1p(movie_stats['count'])\n    top_movies = movie_stats.sort_values('score', ascending=False).head(top_n)\n    \n    return movies[movies['movieId'].isin(top_movies.index)][['movieId', 'title', 'genres']]\n\n# First, let's find the Toy Story movie ID\ntoy_story_movies = movies[movies['title'].str.contains('Toy Story', case=False, na=False)]\nif not toy_story_movies.empty:\n    toy_story_id = toy_story_movies.iloc[0]['movieId']\n    print(f\"Toy Story found with ID: {toy_story_id}\")\n    \n    # Test the improved function\n    improved_item_recs = improved_item_based_recommendations(toy_story_id, movies, item_similarity_df, 5)\n    print(\"Improved item-based recommendations:\")\n    print(improved_item_recs)\nelse:\n    print(\"Toy Story not found in the database\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Experience with an existing user\nsample_user = 1\nprint(\"Recommendations for Existing User\", sample_user)\nprint(recommend_movies_user(sample_user, user_item_matrix, user_similarity_df, movies, top_n=5))\n\n#Experience with a new user (not present in the data)\nnew_user_id = max(user_item_matrix.index) + 1  #Create a new user ID\nprint(f\"\\n Recommendations for New User {new_user_id}\")\nprint(recommend_movies_user(new_user_id, user_item_matrix, user_similarity_df, movies, top_n=5))\n\n#Item-based recommendation function (remains the same)\ndef recommend_similar_movies(movie, movies, item_similarity_df, top_n=10):\n    \"\"\"\n  movie: The movieId can be either an int or a title (string)\n  movies: A table of movies (movieId â†’ title) \n  item_similarity_df: A matrix of similarity between movies\n  top_n: The number of movies that will be returned\n    \"\"\"\n    \n    # If input is title â†’ get its ID\n    if isinstance(movie, str):\n        if movie not in movies[\"title\"].values:\n            raise ValueError(\"Movie title not found!\")\n        movie_id = movies[movies[\"title\"] == movie][\"movieId\"].values[0]\n    else:\n        movie_id = movie\n    \n    # Similarity scores\n    sim_scores = item_similarity_df[movie_id].sort_values(ascending=False).drop(movie_id)\n    \n    # Top N similar\n    top_movies = sim_scores.head(top_n).index\n    return movies[movies[\"movieId\"].isin(top_movies)][[\"movieId\", \"title\"]]\n\nprint(\"\\n Item-based recommendations for movie ID 1:\")\nprint(recommend_similar_movies(1, movies, item_similarity_df, top_n=5))\n\nprint(\"\\n Item-based recommendations for 'Toy Story (1995)':\")\nprint(recommend_similar_movies(\"Toy Story (1995)\", movies, item_similarity_df, top_n=5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef evaluate_precision_at_k(user_id, user_item_matrix, user_similarity_df, movies, k=5):\n    \"\"\"\n    Evaluating the accuracy of recommendations using Precision@K\n    \n    \"\"\"\n    #Data splitting into training and testing\n    user_ratings = user_item_matrix.loc[user_id]\n    rated_movies = user_ratings[user_ratings.notna()].index\n    \n    if len(rated_movies) < 10:  #You need sufficient evaluations for the assessment.\n        return None\n    \n    #Random splitting\n    train_movies, test_movies = train_test_split(rated_movies, test_size=0.2, random_state=42)\n    \n    #Creating a user-item matrix for training\n    train_matrix = user_item_matrix.copy()\n    train_matrix.loc[user_id, test_movies] = np.nan\n    \n    #Recalculate similarity based on training data.\n    train_normalized = normalize_ratings(train_matrix)\n    train_filled = train_normalized.fillna(0)\n    train_similarity = cosine_similarity(train_filled)\n    train_similarity_df = pd.DataFrame(train_similarity, \n                                      index=train_matrix.index, \n                                      columns=train_matrix.index)\n    \n    \n    recommendations = recommend_movies_user(user_id, train_matrix, train_similarity_df, movies, top_n=k)\n    recommended_movies = movies[movies['title'].isin(recommendations)]['movieId'].values\n    \n    # calculate Precision@K\n    relevant_items = set(test_movies)\n    recommended_items = set(recommended_movies)\n    relevant_and_recommended = relevant_items.intersection(recommended_items)\n    \n    return len(relevant_and_recommended) / k\n    \n#evaluation System for multiple users\ndef evaluate_system(user_item_matrix, user_similarity_df, movies, n_users=10, k=5):\n    precisions = []\n    evaluated_users = 0\n    \n    for user_id in user_item_matrix.index[:n_users]:\n        precision = evaluate_precision_at_k(user_id, user_item_matrix, user_similarity_df, movies, k)\n        if precision is not None:\n            precisions.append(precision)\n            evaluated_users += 1\n    \n    if evaluated_users > 0:\n        avg_precision = np.mean(precisions)\n        print(f\"Average Precision@{k} for {evaluated_users} users: {avg_precision:.4f}\")\n        return avg_precision\n    else:\n        print(\"Not enough data for evaluation\")\n        return None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef improved_svd_recommendations(user_id, top_n=5):\n    \"\"\"\n    Using the Surprise library to improve SVD\n    \"\"\"\n    #Preparing the data for Surprise format\n    reader = Reader(rating_scale=(1, 5))\n    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n    \n    #Using SVD with regularization\n    algo = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n    \n    #Training on the full data\n    trainset = data.build_full_trainset()\n    algo.fit(trainset)\n    \n    #Generate recommendations\n    user_inner_id = trainset.to_inner_uid(user_id)\n    user_ratings = trainset.ur[user_inner_id]\n    \n    #Getting predictions for all movies\n    predictions = []\n    for movie_inner_id in range(trainset.n_items):\n        pred = algo.predict(user_id, trainset.to_raw_iid(movie_inner_id))\n        predictions.append((pred.iid, pred.est))\n    \n    #Sorting recommendations\n    predictions.sort(key=lambda x: x[1], reverse=True)\n\n    #Exclude the movies that the user has watched.\n    user_watched = [trainset.to_raw_iid(movie_inner_id) for movie_inner_id, _ in user_ratings]\n    recommendations = [movie for movie, rating in predictions if movie not in user_watched]\n    \n    return movies[movies['movieId'].isin(recommendations[:top_n])]['title'].tolist()\n\n#Testing the improved SVD\nprint(\"Improved SVD Recommendations:\")\nimproved_svd_recs = improved_svd_recommendations(1, 5)\nprint(improved_svd_recs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def matrix_factorization_recommendations(user_id, user_item_matrix, movies, top_n=5):\n    \"\"\"\n    Generating recommendations using matrix factorization (SVD)\n    \"\"\"\n    try:\n        #Converting the array to numerical values\n        R = user_item_matrix.fillna(0).values\n        \n        # Applay SVD\n        U, sigma, Vt = np.linalg.svd(R, full_matrices=False)\n        sigma = np.diag(sigma)\n        \n        #Rebuild the array with predictions\n        predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n        predicted_df = pd.DataFrame(predicted_ratings, \n                                   index=user_item_matrix.index, \n                                   columns=user_item_matrix.columns)\n        \n        # Getting predictions for the user\n        user_predictions = predicted_df.loc[user_id]\n        \n        # Remove the movies that the user has already watched.\n        user_ratings = user_item_matrix.loc[user_id]\n        already_rated = user_ratings[user_ratings.notna()].index\n        user_predictions = user_predictions.drop(already_rated, errors='ignore')\n        \n        # Getting the best recommendations\n        top_movies = user_predictions.sort_values(ascending=False).head(top_n)\n        \n        return movies.set_index(\"movieId\").loc[top_movies.index][\"title\"]\n    \n    except Exception as e:\n        print(f\"SVD Error: {e}\")\n        # Going back to the recommendations based on the user.\n        return recommend_movies_user(user_id, user_item_matrix, user_similarity_df, movies, top_n)\n\ndef recommend_movies(user_id, method='user_based', top_n=5):\n    \"\"\"\n    A unified recommendation function that supports multiple methods\n    \"\"\"\n    if method == 'user_based':\n        return recommend_movies_user(user_id, user_item_matrix, user_similarity_df, movies, top_n)\n    elif method == 'item_based':\n        # To obtain based on items, we need a reference movie.\n        # We use the movie Toy Story as a default.\n        return recommend_similar_movies(1, movies, item_similarity_df, top_n)\n    elif method == 'svd':\n        return matrix_factorization_recommendations(user_id, user_item_matrix, movies, top_n)\n    else:\n        raise ValueError(\"Method must be 'user_based', 'item_based', or 'svd'\")\n\ndef recommend_similar_movies(movie_id, movies, item_similarity_df, top_n=5):\n    \"\"\"\n    The recommendation based on similar movies\n    \"\"\"\n    try:\n        # Getting similarity scores\n        sim_scores = item_similarity_df[movie_id].sort_values(ascending=False)\n        \n        #Removing the film\n        sim_scores = sim_scores.drop(movie_id, errors='ignore')\n        \n        # Getting the best similar movies\n        top_movies = sim_scores.head(top_n).index\n        \n        return movies[movies['movieId'].isin(top_movies)][[\"movieId\", \"title\"]]\n    \n    except Exception as e:\n        print(f\"Item-based recommendation error: {e}\")\n        # Back to popular movies\n        movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n        movie_stats = movie_stats[movie_stats['count'] > 10]\n        movie_stats['score'] = movie_stats['mean'] * np.log1p(movie_stats['count'])\n        top_movies = movie_stats.sort_values('score', ascending=False).head(top_n)\n        return movies[movies['movieId'].isin(top_movies.index)][[\"movieId\", \"title\"]]\n\ndef recommend_movies_user(user_id, user_item_matrix, user_similarity_df, movies, top_n=5):\n    \"\"\"\n   The recommendation is \n   based on similar users.\n    \"\"\"\n    try:\n        # User Ratings\n        user_ratings = user_item_matrix.loc[user_id]\n        \n        # similar_users\n        similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:11]\n\n        # Calculation of Weighted Ratings\n        weighted_scores = pd.Series(dtype=float)\n        for neighbor_id, sim_score in similar_users.items():\n            neighbor_ratings = user_item_matrix.loc[neighbor_id]\n            weighted_scores = weighted_scores.add(neighbor_ratings * sim_score, fill_value=0)\n        \n        # Normalization of results\n        sim_sums = similar_users.sum()\n        predicted_ratings = weighted_scores / sim_sums\n        \n        # Remove watched movies\n        already_seen = user_ratings[user_ratings.notna()].index\n        predicted_ratings = predicted_ratings.drop(already_seen, errors='ignore')\n        \n        # Getting the best recommendations\n        top_movies = predicted_ratings.sort_values(ascending=False).head(top_n)\n        \n        return movies.set_index(\"movieId\").loc[top_movies.index][\"title\"].tolist()\n    \n    except Exception as e:\n        print(f\"User-based recommendation error: {e}\")\n        #Back to the popular movies\n        movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n        movie_stats = movie_stats[movie_stats['count'] > 10]\n        movie_stats['score'] = movie_stats['mean'] * np.log1p(movie_stats['count'])\n        top_movies = movie_stats.sort_values('score', ascending=False).head(top_n)\n        return movies[movies['movieId'].isin(top_movies.index)]['title'].tolist()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Activate the evaluation function.\nprint(\"\\n\" + \"=\"*50)\nprint(\"Evaluate the system's performance\")\nprint(\"=\"*50)\n\n# Evaluation of the system on the first 15 users\navg_precision = evaluate_system(user_item_matrix, user_similarity_df, movies, n_users=15, k=5)\nprint(f\"Precision@5 Average : {avg_precision:.4f}\")\n\n# Try SVD Recommendation \nprint(\"\\n\" + \"=\"*50)\nprint(\"Recommendations using Singular Value Decomposition (SVD)\")\nprint(\"=\"*50)\n\n# Try SVD  for an Existing User\ntry:\n    svd_recommendations = matrix_factorization_recommendations(1, user_item_matrix, movies, top_n=5)\n    print(f\"recommendations SVD for user 1: {svd_recommendations.tolist()}\")\nexcept Exception as e:\n    print(f\" Error in SVD: {e}\")\n\n# Unified recommendation function test\nprint(\"\\n\" + \"=\"*50)\nprint(\"Unified recommendation function test\")\nprint(\"=\"*50)\n\n\n# Searching for the Toy Story movie ID\ntoy_story_id = movies[movies['title'].str.contains('Toy Story')]['movieId'].values[0]\nprint(f\"Toy Story movie ID: {toy_story_id}\")\n\n# Testing All Recommendation Methods\nmethods = ['user_based', 'item_based', 'svd']\n\nfor method in methods:\n    try:\n        if method == 'item_based':\n            # To recommend based on items, we need to pass the movie ID.\n            recommendations = recommend_similar_movies(toy_story_id, movies, item_similarity_df, top_n=5)\n            print(f\"\\n Recommendations {method} based on Toy Story:\")\n            print(recommendations)\n        else:\n            recommendations = recommend_movies(1, method=method, top_n=5)\n            print(f\"\\n Recommendations {method} For user 1: {recommendations}\")\n    except Exception as e:\n        print(f\" Error in {method}: {e}\")\n\n\n#Comparison of different recommendation methods\nprint(\"\\n\" + \"=\"*50)\nprint(\" Comparison of different recommendation methods\")\nprint(\"=\"*50)\n\n#Comparison of recommendations for user 1 using different methods\nuser_id = 1\n\nprint(f\"User: {user_id}\")\nprint(\"-\" * 30)\n\n# recommendation based on users\nuser_based_recs = recommend_movies(user_id, 'user_based', 5)\nprint(f\"recommendation based on users: {user_based_recs}\")\n\n# Recommendation based on items (using a favorite movie of the user)\n# Let's assume that the movie Toy Story is one of his favorite films.\nitem_based_recs = recommend_similar_movies(toy_story_id, movies, item_similarity_df, 5)\nprint(f\"Recommendation based on items ( based on Toy Story):\")\nprint(item_based_recs)\n\n# Recommendation using SVD\nsvd_recs = recommend_movies(user_id, 'svd', 5)\nprint(f\"Recommendation using SVD : {svd_recs}\")","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-08-25T05:27:21.242249Z","shell.execute_reply.started":"2025-08-25T05:24:57.579682Z","shell.execute_reply":"2025-08-25T05:27:21.241439Z"}},"outputs":[{"name":"stdout","text":"\n Recommendations svd For user 1: movieId\n2                Jumanji (1995)\n142     Shadows (Cienie) (1988)\n10             GoldenEye (1995)\n1380              Grease (1978)\n1614            In & Out (1997)\nName: title, dtype: object\n\n==================================================\n Comparison of different recommendation methods\n==================================================\nUser: 1\n------------------------------\nrecommendation based on users: ['Little Mermaid, The (1989)', 'Jungle Book, The (1967)', 'Sleeping Beauty (1959)', 'Lion King, The (1994)', 'Fantasia (1940)']\nRecommendation based on items ( based on Toy Story):\n      movieId                      title\n584       588             Aladdin (1992)\n1245     1265       Groundhog Day (1993)\n1250     1270  Back to the Future (1985)\n2286     2355       Bug's Life, A (1998)\n3045     3114         Toy Story 2 (1999)\nRecommendation using SVD : movieId\n2                Jumanji (1995)\n142     Shadows (Cienie) (1988)\n10             GoldenEye (1995)\n1380              Grease (1978)\n1614            In & Out (1997)\nName: title, dtype: object\n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"def analyze_precision_issues():\n    \"\"\"\n    A detailed analysis of the relatively low accuracy reasons.\n    \"\"\"\n    # Study of the distribution of ratings\n    rating_distribution = ratings['rating'].value_counts().sort_index()\n    print(\"Distribution of ratings:\")\n    print(rating_distribution)\n    \n    # Study the number of ratings per user\n    user_rating_counts = ratings.groupby('userId')['movieId'].count()\n    print(f\"\\n Average ratings per user: {user_rating_counts.mean():.2f}\")\n    print(f\" Min user ratings : {user_rating_counts.min()}\")\n    print(f\" Max user ratings: {user_rating_counts.max()}\")\n    \n    #Sparsity analysis of the matrix\n    matrix_size = user_item_matrix.shape[0] * user_item_matrix.shape[1]\n    non_na_count = user_item_matrix.count().sum()\n    sparsity = 1 - (non_na_count / matrix_size)\n    print(f\"\\nSparsity matrix: {sparsity:.4f} ({sparsity*100:.2f}%)\")\n    \n    return sparsity\n\nmatrix_sparsity = analyze_precision_issues()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:27:21.243193Z","iopub.execute_input":"2025-08-25T05:27:21.243808Z","iopub.status.idle":"2025-08-25T05:27:21.355473Z","shell.execute_reply.started":"2025-08-25T05:27:21.243778Z","shell.execute_reply":"2025-08-25T05:27:21.354711Z"}},"outputs":[{"name":"stdout","text":"Distribution of ratings:\nrating\n1     56174\n2    107557\n3    261197\n4    348971\n5    226310\nName: count, dtype: int64\n\n Average ratings per user: 165.60\n Min user ratings : 20\n Max user ratings: 2314\n\nSparsity matrix: 0.9553 (95.53%)\n","output_type":"stream"}],"execution_count":133},{"cell_type":"code","source":"train_ratings, test_ratings = train_test_split(ratings, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:27:21.356347Z","iopub.execute_input":"2025-08-25T05:27:21.356686Z","iopub.status.idle":"2025-08-25T05:27:21.454720Z","shell.execute_reply.started":"2025-08-25T05:27:21.356656Z","shell.execute_reply":"2025-08-25T05:27:21.453917Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"\ndef evaluate_svd_with_surprise_fast():\n    \"\"\"\n    SVD evaluation using the Surprise library.\n    \"\"\"\n    # prepar Data\n    reader = Reader(rating_scale=(1, 5))\n    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n    \n    # Split Data\n    trainset, testset = surprise_train_test_split(data, test_size=0.2, random_state=42)\n    \n    # Training Model\n    algo = SVD(n_factors=100, n_epochs=20, lr_all=0.005, reg_all=0.02)\n    algo.fit(trainset)\n    \n    # predictions and Evaluation\n    predictions = algo.test(testset)\n    \n \n    rmse = accuracy.rmse(predictions)\n    mae = accuracy.mae(predictions)\n    \n    print(f\"RMSE: {rmse:.4f}\")\n    print(f\"MAE: {mae:.4f}\")\n    \n     #Calculating Precision@K more efficiently\n    def precision_at_k_fast(predictions, k=5, threshold=4):\n        \"\"\"\n        Calculating Precision@K  \n        \"\"\"\n        # Creating a dictionary for quick access to real ratings.\n        true_ratings_dict = {}\n        for uid, iid, true_r, est, _ in predictions:\n            if uid not in true_ratings_dict:\n                true_ratings_dict[uid] = {}\n            true_ratings_dict[uid][iid] = true_r\n        \n        # Aggregating predictions for each user\n        user_predictions = defaultdict(list)\n        for uid, iid, true_r, est, _ in predictions:\n            user_predictions[uid].append((iid, est))\n        \n        # Calculating Precision@K for all users \n        precisions = []\n        for uid, preds in user_predictions.items():\n            \n            # Sort the predictions in descending order\n            preds.sort(key=lambda x: x[1], reverse=True)\n            \n            # Top K Recommendations\n            top_k = preds[:k]\n            \n            # Calculating Hits\n            hits = 0\n            for iid, est in top_k:\n                true_rating = true_ratings_dict[uid].get(iid, None)\n                if true_rating is not None and true_rating >= threshold:\n                    hits += 1\n            \n            precision = hits / k\n            precisions.append(precision)\n        \n        return np.mean(precisions) if precisions else 0\n    \n    # Calculating Precision@K  \n    precision = precision_at_k_fast(predictions, k=5, threshold=4)\n    print(f\"Precision@5: {precision:.4f}\")\n    \n    return rmse, mae, precision\n\nrmse, mae, precision = evaluate_svd_with_surprise_fast()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:27:21.455584Z","iopub.execute_input":"2025-08-25T05:27:21.455891Z","iopub.status.idle":"2025-08-25T05:27:40.175815Z","shell.execute_reply.started":"2025-08-25T05:27:21.455871Z","shell.execute_reply":"2025-08-25T05:27:40.174864Z"}},"outputs":[{"name":"stdout","text":"RMSE: 0.8733\nMAE:  0.6846\nRMSE: 0.8733\nMAE: 0.6846\nPrecision@5: 0.7872\n","output_type":"stream"}],"execution_count":135},{"cell_type":"code","source":"def final_recommendation_system(user_id, top_n=10):\n    \"\"\"\n    The final system that combines power and precision.\n\n    \"\"\"\n    #For new users: Popular movies\n    if user_id not in ratings['userId'].values:\n        return get_popular_movies(movies, top_n)\n    \n    #For old users: SVD with Surprise\n    reader = Reader(rating_scale=(1, 5))\n    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n    \n    #Using the best parameters\n    algo = SVD(n_factors=100, n_epochs=25, lr_all=0.007, reg_all=0.1)\n    trainset = data.build_full_trainset()\n    algo.fit(trainset)\n    \n    #recommendations\n    testset = trainset.build_anti_testset()\n    user_testset = [x for x in testset if x[0] == user_id]\n    predictions = algo.test(user_testset)\n    \n    # Sort and Top recommendations\n    predictions.sort(key=lambda x: x.est, reverse=True)\n    top_predictions = predictions[:top_n]\n    \n    #Getting the movie titles\n    recommended_ids = [int(pred.iid) for pred in top_predictions]\n    recommended_movies = movies[movies['movieId'].isin(recommended_ids)]\n    \n    return recommended_movies[['movieId', 'title', 'genres']]\n\n#Try the final system\nprint(\"final recommendations for user 1:\")\nfinal_recommendations = final_recommendation_system(1, 10)\nprint(final_recommendations)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:27:40.178020Z","iopub.execute_input":"2025-08-25T05:27:40.178263Z","iopub.status.idle":"2025-08-25T05:28:07.106777Z","shell.execute_reply.started":"2025-08-25T05:27:40.178245Z","shell.execute_reply":"2025-08-25T05:28:07.105998Z"}},"outputs":[{"name":"stdout","text":"final recommendations for user 1:\n      movieId                                              title  \\\n52         53                                    Lamerica (1994)   \n315       318                   Shawshank Redemption, The (1994)   \n892       904                                 Rear Window (1954)   \n1132     1148                         Wrong Trousers, The (1993)   \n1242     1262                           Great Escape, The (1963)   \n1950     2019  Seven Samurai (The Magnificent Seven) (Shichin...   \n2128     2197                                   Firelight (1997)   \n2434     2503                            Apple, The (Sib) (1998)   \n2836     2905                                     Sanjuro (1962)   \n3269     3338                             For All Mankind (1989)   \n\n                genres  \n52               Drama  \n315              Drama  \n892   Mystery|Thriller  \n1132  Animation|Comedy  \n1242     Adventure|War  \n1950      Action|Drama  \n2128             Drama  \n2434             Drama  \n2836  Action|Adventure  \n3269       Documentary  \n","output_type":"stream"}],"execution_count":136},{"cell_type":"code","source":"def recommend_movies_user(user_id, user_item_matrix, user_similarity_df, movies, top_n=5):\n    \"\"\"\n    Recommendations based on the user with support for the required number of recommendations - modified version.\n    \"\"\"\n    try:\n        # user ratings\n        user_ratings = user_item_matrix.loc[user_id]\n        \n        # similar_users\n        similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:11]\n        \n        # Calculate weighted_scores\n        weighted_scores = pd.Series(dtype=float)\n        for neighbor_id, sim_score in similar_users.items():\n            neighbor_ratings = user_item_matrix.loc[neighbor_id]\n            weighted_scores = weighted_scores.add(neighbor_ratings * sim_score, fill_value=0)\n        \n        sim_sums = similar_users.sum()\n        predicted_ratings = weighted_scores / sim_sums\n        \n        # Remove Already seen Movies \n        already_seen = user_ratings[user_ratings.notna()].index\n        predicted_ratings = predicted_ratings.drop(already_seen, errors='ignore')\n        \n        #Getting the best recommendations - use top_n here\n        top_movies = predicted_ratings.sort_values(ascending=False).head(top_n)\n        \n        return movies.set_index(\"movieId\").loc[top_movies.index][\"title\"].tolist()\n    \n    except Exception as e:\n        print(f\"Error in user-based recommendations: {e}\")\n        # Fallback to popular movies\n        movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n        movie_stats = movie_stats[movie_stats['count'] > 10]\n        movie_stats['score'] = movie_stats['mean'] * np.log1p(movie_stats['count'])\n        top_movies = movie_stats.sort_values('score', ascending=False).head(top_n)\n        return movies[movies['movieId'].isin(top_movies.index)]['title'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:28:07.107603Z","iopub.execute_input":"2025-08-25T05:28:07.108399Z","iopub.status.idle":"2025-08-25T05:28:07.116827Z","shell.execute_reply.started":"2025-08-25T05:28:07.108377Z","shell.execute_reply":"2025-08-25T05:28:07.115900Z"}},"outputs":[],"execution_count":137},{"cell_type":"code","source":"!pip install gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:28:07.117903Z","iopub.execute_input":"2025-08-25T05:28:07.118220Z","iopub.status.idle":"2025-08-25T05:28:11.162698Z","shell.execute_reply.started":"2025-08-25T05:28:07.118189Z","shell.execute_reply":"2025-08-25T05:28:11.161577Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.13)\nRequirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\nRequirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\nRequirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nRequirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\nRequirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.5.1)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","output_type":"stream"}],"execution_count":138},{"cell_type":"code","source":"import gradio as gr\nimport pandas as pd\nimport numpy as np\n\ndef item_based_recommendation_gradio(movie_input, top_n=5, min_similarity=0.1):\n    \"\"\"\n    Item-based recommendation system for Gradio\n    \"\"\"\n    try:\n        # Find the movie\n        if movie_input.isdigit():\n            # If movie ID is entered\n            movie_id = int(movie_input)\n            movie_info = movies[movies['movieId'] == movie_id]\n            if len(movie_info) == 0:\n                return \"âŒ No movie found with this ID\", None\n            movie_title = movie_info.iloc[0]['title']\n            movie_id = movie_info.iloc[0]['movieId']\n        else:\n            # If movie name is entered\n            movie_match = movies[movies['title'].str.contains(movie_input, case=False, na=False)]\n            if len(movie_match) == 0:\n                return \"âŒ No movie found with this name\", None\n            movie_id = movie_match.iloc[0]['movieId']\n            movie_title = movie_match.iloc[0]['title']\n        \n        # Check if movie exists in similarity matrix\n        if movie_id not in item_similarity_df.columns:\n            return \"âŒ This movie is not in the database\", None\n        \n        # Get similar movies\n        similar_movies = item_similarity_df[movie_id].sort_values(ascending=False)\n        \n        # Remove the movie itself and apply similarity threshold\n        similar_movies = similar_movies.drop(movie_id, errors='ignore')\n        similar_movies = similar_movies[similar_movies >= min_similarity]\n        \n        if len(similar_movies) == 0:\n            return \"âŒ Not enough similar movies found\", None\n        \n        # Get top recommendations\n        top_recommendations = similar_movies.head(top_n)\n        \n        # Create results table\n        results = []\n        for similar_movie_id, similarity_score in top_recommendations.items():\n            movie_info = movies[movies['movieId'] == similar_movie_id].iloc[0]\n            results.append({\n                \"Movie\": movie_info['title'],\n                \"Similarity Score\": f\"{similarity_score:.3f}\",\n                \"Genres\": movie_info['genres'],\n                \"Movie ID\": similar_movie_id\n            })\n        \n        results_df = pd.DataFrame(results)\n        return f\"ðŸŽ¯ Top {len(results)} movies similar to '{movie_title}':\", results_df\n        \n    except Exception as e:\n        return f\"âŒ Error occurred: {e}\", None\n\ndef user_based_recommendation_gradio(user_id, top_n=5):\n    \"\"\"\n    User-based recommendation system for Gradio\n    \"\"\"\n    try:\n        user_id = int(user_id)\n        \n        # Check if user exists\n        if user_id not in ratings['userId'].values:\n            # For new users, show popular movies\n            movie_stats = ratings.groupby('movieId')['rating'].agg(['count', 'mean'])\n            movie_stats = movie_stats[movie_stats['count'] > 10]\n            movie_stats['score'] = movie_stats['mean'] * np.log1p(movie_stats['count'])\n            top_movies = movie_stats.sort_values('score', ascending=False).head(top_n)\n            popular_movies = movies[movies['movieId'].isin(top_movies.index)]\n            \n            results = []\n            for _, movie in popular_movies.iterrows():\n                results.append({\n                    \"Movie\": movie['title'],\n                    \"Genres\": movie['genres'],\n                    \"Rating\": f\"{top_movies.loc[movie['movieId'], 'mean']:.2f}\",\n                    \"Number of Ratings\": int(top_movies.loc[movie['movieId'], 'count'])\n                })\n            \n            results_df = pd.DataFrame(results)\n            return f\"ðŸŽ¯ Popular movies for new user {user_id}:\", results_df\n        \n        # User-based recommendation\n        recommendations = recommend_movies_user(user_id, user_item_matrix, user_similarity_df, movies, top_n)\n        \n        results = []\n        for movie_title in recommendations:\n            movie_info = movies[movies['title'] == movie_title].iloc[0]\n            results.append({\n                \"Movie\": movie_info['title'],\n                \"Genres\": movie_info['genres'],\n                \"Movie ID\": movie_info['movieId']\n            })\n        \n        results_df = pd.DataFrame(results)\n        return f\"ðŸŽ¯ Top {top_n} recommendations for user {user_id}:\", results_df\n        \n    except Exception as e:\n        return f\"âŒ Error occurred: {e}\", None\n\n# Create Gradio interface\nwith gr.Blocks(title=\"Movie Recommendation System\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"# ðŸŽ¬ Movie Recommendation System\")\n    gr.Markdown(\"## Choose your preferred recommendation method\")\n    \n    with gr.Tab(\"Item-Based Recommendations\"):\n        gr.Markdown(\"### ðŸ” Find movies similar to your favorite\")\n        with gr.Row():\n            movie_input = gr.Textbox(label=\"Movie Name or ID\", placeholder=\"Enter 'Toy Story' or '1'\")\n            top_n_similar = gr.Slider(minimum=1, maximum=20, value=5, step=1, label=\"Number of Recommendations\")\n        \n        movie_btn = gr.Button(\"Find Similar Movies\")\n        movie_output_text = gr.Textbox(label=\"Result\")\n        movie_output_df = gr.Dataframe(label=\"Recommended Movies\")\n    \n    with gr.Tab(\"User-Based Recommendations\"):\n        gr.Markdown(\"### ðŸ‘¤ Get personalized recommendations based on your preferences\")\n        with gr.Row():\n            user_input = gr.Textbox(label=\"User ID\", placeholder=\"Enter user ID (e.g., 1)\")\n            top_n_user = gr.Slider(minimum=1, maximum=20, value=5, step=1, label=\"Number of Recommendations\")\n        \n        user_btn = gr.Button(\"Get Recommendations\")\n        user_output_text = gr.Textbox(label=\"Result\")\n        user_output_df = gr.Dataframe(label=\"Recommended Movies\")\n    \n    with gr.Tab(\"Explore Movies\"):\n        gr.Markdown(\"### ðŸ“Š Explore the movie database\")\n        genre_filter = gr.Dropdown(label=\"Select Genre\", choices=sorted(movies['genres'].str.split('|').explode().unique()))\n        explore_btn = gr.Button(\"Show Movies\")\n        explore_output = gr.Dataframe(label=\"Movies\")\n        \n        def explore_movies(genre):\n            if genre:\n                filtered_movies = movies[movies['genres'].str.contains(genre, na=False)]\n                return filtered_movies[['title', 'genres', 'movieId']].head(20)\n            return movies[['title', 'genres', 'movieId']].head(20)\n    \n    # Connect buttons to functions\n    movie_btn.click(\n        fn=item_based_recommendation_gradio,\n        inputs=[movie_input, top_n_similar],\n        outputs=[movie_output_text, movie_output_df]\n    )\n    \n    user_btn.click(\n        fn=user_based_recommendation_gradio,\n        inputs=[user_input, top_n_user],\n        outputs=[user_output_text, user_output_df]\n    )\n    \n    explore_btn.click(\n        fn=explore_movies,\n        inputs=[genre_filter],\n        outputs=[explore_output]\n    )\n    \n    gr.Markdown(\"---\")\n    gr.Markdown(\"### ðŸ’¡ Examples to try:\")\n    gr.Markdown(\"- **Movies**: 'Toy Story', 'Titanic'  , 'Avengers' \")\n    gr.Markdown(\"- **Movie IDs**: 1, 318, 858, 260\")\n    gr.Markdown(\"- **User IDs**: 1, 5, 10, 15\")\n    gr.Markdown(\"- **Genres**: Drama, Comedy, Action, Adventure\")\n\n# Run the application\nif __name__ == \"__main__\":\n    demo.launch(share=True)  # share=True to create a public link     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:41:59.185645Z","iopub.execute_input":"2025-08-25T05:41:59.186005Z","iopub.status.idle":"2025-08-25T05:42:01.511290Z","shell.execute_reply.started":"2025-08-25T05:41:59.185983Z","shell.execute_reply":"2025-08-25T05:42:01.510592Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7867\n* Running on public URL: https://8b161f11b1b926021e.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://8b161f11b1b926021e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":145},{"cell_type":"code","source":"import joblib\nfrom surprise import dump\n\ndef save_recommendation_model():\n    \"\"\"\n    save model \n    \"\"\"\n    #  train model\n    reader = Reader(rating_scale=(1, 5))\n    data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n    algo = SVD(n_factors=100, n_epochs=25, lr_all=0.007, reg_all=0.1)\n    trainset = data.build_full_trainset()\n    algo.fit(trainset)\n    \n    # save model\n    dump.dump('movie_recommender_model', algo=algo)\n    \n    #Save reference data\n    joblib.dump({\n        'movies': movies,\n        'ratings': ratings,\n        'user_item_matrix': user_item_matrix\n    }, 'movie_data.pkl')\n    \n    print(\"The model and data have been saved successfully.\")\n\ndef load_recommendation_model():\n    \"\"\"\n    Download the saved model\n    \"\"\"\n    try:\n        algo = dump.load('movie_recommender_model')[1]\n        data = joblib.load('movie_data.pkl')\n        return algo, data['movies'], data['ratings'], data['user_item_matrix']\n    except:\n        print(\" No saved model found\")\n        return None, None, None, None\n\nsave_recommendation_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-25T05:32:19.236248Z","iopub.execute_input":"2025-08-25T05:32:19.236961Z","iopub.status.idle":"2025-08-25T05:32:37.263879Z","shell.execute_reply.started":"2025-08-25T05:32:19.236938Z","shell.execute_reply":"2025-08-25T05:32:37.262832Z"}},"outputs":[{"name":"stdout","text":"The model and data have been saved successfully.\n","output_type":"stream"}],"execution_count":142}]}